{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix :: Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib.request\n",
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import matplotlib\n",
    "import bisect\n",
    "import math\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import warnings\n",
    "import country_converter as coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!{sys.executable} -m pip install country_converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_module_path = './'\n",
    "module_path = os.path.abspath(os.path.join(user_module_path))\n",
    "\n",
    "import fetch_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload_module(module,\n",
    "                 user_module_path = './'):\n",
    "    # Block to handle reloading user modules\n",
    "    module_path = os.path.abspath(os.path.join(user_module_path))\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "    importlib.reload(module)\n",
    "    fetch_data.test_refresh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_warnings(level):\n",
    "    # Disable warnings\n",
    "    warnings.filterwarnings(level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_df(df, days=30):\n",
    "    plt.title(\"Per day\")\n",
    "    plt.plot(df.index[-days:], df['confirmed'][-days:], label=\"Confirmed\")\n",
    "    plt.plot(df.index[-days:], df['deaths'][-days:], label=\"Deaths\")\n",
    "    plt.plot(df.index[-days:], df['recovered'][-days:], label=\"Recovered\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "#     plt.title(\"2nd diff\")\n",
    "#     plt.plot(df.index[-days:], df['confirmed_diff_2'][-days:], label=\"Confirmed\")\n",
    "#     plt.plot(df.index[-days:], df['deaths_diff_2'][-days:], label=\"Deaths\")\n",
    "#     plt.plot(df.index[-days:], df['recovered_diff_2'][-days:], label=\"Recovered\")\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "    plt.title(\"Cumulative, Linear\")\n",
    "    plt.plot(df.index[-days:], df['confirmed_total'][-days:], label=\"Confirmed\")\n",
    "    plt.plot(df.index[-days:], df['deaths_total'][-days:], label=\"Deaths\")\n",
    "    plt.plot(df.index[-days:], df['recovered_total'][-days:], label=\"Recovered\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.title(\"Cumulative, Log\")\n",
    "    plt.plot(df.index[-days:], df['confirmed_log_total'][-days:], label=\"Confirmed\")\n",
    "    plt.plot(df.index[-days:], df['deaths_log_total'][-days:], label=\"Deaths\")\n",
    "    plt.plot(df.index[-days:], df['recovered_log_total'][-days:], label=\"Recovered\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.title(\"Per day, Log\")\n",
    "    plt.plot(df.index[-days:], df['confirmed_log'][-days:], label=\"Confirmed\")\n",
    "    plt.plot(df.index[-days:], df['deaths_log'][-days:], label=\"Deaths\")\n",
    "    plt.plot(df.index[-days:], df['recovered_log'][-days:], label=\"Recovered\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_set(series,\n",
    "             panels = 3,\n",
    "             col_width  = 7,\n",
    "             row_height = 5,\n",
    "             fig_title=\"Title\"):\n",
    "    # Calculate the number of rows\n",
    "    row_max, col_max, del_cells = calc_maxes(len(series), panels)\n",
    "    fig, axs = plt.subplots(row_max, col_max)\n",
    "    fig.set_size_inches(col_max * col_width, row_max * row_height)\n",
    "    fig.suptitle(fig_title)\n",
    "\n",
    "    row_idx = 0\n",
    "    col_idx = 0\n",
    "\n",
    "    # Handle single row case\n",
    "    if (row_max == 1):\n",
    "        for s in series:\n",
    "            axs[col_idx].plot(s)\n",
    "            col_idx += 1\n",
    "    # Multirow case\n",
    "    else:\n",
    "        for s in series:\n",
    "            axs[row_idx, col_idx].plot(s)\n",
    "            col_idx += 1\n",
    "            if (col_idx == col_max):\n",
    "                row_idx += 1\n",
    "                col_idx = 0\n",
    "\n",
    "    # Hide extra panels\n",
    "    offset = col_max - del_cells\n",
    "    for i in range(0, del_cells):\n",
    "        axs[row_max-1, offset+i].axis('off')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebase_series(series, threshold=0, ret_idx = False, trim_idx = -1):\n",
    "    if (trim_idx == -1):\n",
    "        trim_idx = bisect.bisect_left(series, threshold)\n",
    "    trim_series = np.array(list(series[trim_idx:].values) + [np.nan]*trim_idx)\n",
    "    if ret_idx:\n",
    "        return trim_series, trim_idx\n",
    "    else:\n",
    "        return trim_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_plot(df,\n",
    "                   countries,\n",
    "                   threshold=25,\n",
    "                   x_lim=45,\n",
    "                   y_lim=None,\n",
    "                   log_var = False):\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    plt.subplots_adjust(wspace=0.4)\n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(16, 8)\n",
    "    fig.suptitle(\"Cross Country comparisons of growth rates\")\n",
    "    \n",
    "    plot_var = \"deaths_total\"\n",
    "    if log_var:\n",
    "        threshold = math.log(threshold)\n",
    "    #plt.figure(figsize=(10,7))\n",
    "    #plt.title(f\"Total coronavirus deaths for places with at least {threshold} deaths\")\n",
    "    \n",
    "    deaths_threshold = 25\n",
    "    confirmed_threshold = 1000\n",
    "    \n",
    "    #y_ticks = [1, 2000-threshold, 5000-threshold, 20000-threshold]\n",
    "    #y_tick_labels = [threshold, 2000, 5000, 20000]\n",
    "#     max_region_st = 0\n",
    "    for c in countries:\n",
    "        country_df = df.loc[df[\"Country/Region\"]==c]\n",
    "        \n",
    "        deaths_rebase = rebase_series(country_df['deaths_total'], threshold=deaths_threshold)\n",
    "        axs[0].plot(deaths_rebase-deaths_threshold, label=c)\n",
    "        \n",
    "        confirmed_rebase = rebase_series(country_df['confirmed_total'], threshold=confirmed_threshold)\n",
    "        axs[1].plot(confirmed_rebase-confirmed_threshold, label=c)\n",
    "#         if region_st > max_region_st:\n",
    "#             max_region_st = region_st\n",
    "    #print(f\"region_st {len(region_st)}\")\n",
    "        x = np.linspace(0,len(region_st),len(region_st))\n",
    "\n",
    "        # Add scale lines\n",
    "    for idx in [0,1]:\n",
    "        axs[idx].plot(np.power(2,x), color=\"#666666\")\n",
    "        axs[idx].plot(np.power(2,x/2), color=\"#666666\")\n",
    "        axs[idx].plot(np.power(2,x/3), color=\"#666666\")\n",
    "        axs[idx].plot(np.power(2,x/7), color=\"#666666\")\n",
    "        axs[idx].plot(np.power(2,x/30), color=\"#666666\")\n",
    "        axs[idx].set_xlim((0,x_lim))\n",
    "        axs[idx].set_yscale(\"log\", basey=2)                                 \n",
    "        axs[idx].legend(loc=\"upper right\")                         \n",
    "        \n",
    "    axs[0].set_xlabel(f\"Days since {deaths_threshold}th death\")\n",
    "    axs[1].set_xlabel(f\"Days since {confirmed_threshold}th confirmed case\")\n",
    "\n",
    "    if y_lim is not None:\n",
    "        axs[0].set_ylim((1,y_lim))\n",
    "        axs[1].set_ylim((1,y_lim*8))\n",
    "\n",
    "    axs[0].set_title(f\"Total Deaths\")\n",
    "    axs[1].set_title(f\"Total Confirmed Cases\")\n",
    "\n",
    "    axs[0].set_yticks([1,100-deaths_threshold,200-deaths_threshold,500-deaths_threshold,\n",
    "                       1000-deaths_threshold,2000-deaths_threshold,5000-deaths_threshold,\n",
    "                       10_000-deaths_threshold,20_000-deaths_threshold])\n",
    "    axs[0].set_yticklabels([deaths_threshold,100,200,500,1000,2000,5000,10_000,20_000])\n",
    "\n",
    "    axs[1].set_yticks([1,#100-confirmed_threshold,200-confirmed_threshold,500-confirmed_threshold,\n",
    "                       2000-confirmed_threshold,5000-confirmed_threshold,\n",
    "                       10_000-confirmed_threshold,20_000-confirmed_threshold,50_000-confirmed_threshold,\n",
    "                       100_000-confirmed_threshold,200_000-confirmed_threshold,500_000-confirmed_threshold,\n",
    "                       1_000_000-confirmed_threshold])\n",
    "    axs[1].set_yticklabels([confirmed_threshold,2000,5000,10_000,20_000,50_000,100_000,\n",
    "                            200_000,500_000,1_000_000])\n",
    "    #axs[idx].get_yaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "    plt.savefig(f'figures/country_set_timeComp_{threshold}.png')\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_panel(axs, row_idx, col_idx, country_df, plot_vars, threshold, title, log_scale = False, mean_window=1):\n",
    "    first = True\n",
    "    for plot_var in plot_vars.keys():\n",
    "        if first:\n",
    "            series, trim_idx = rebase_series(country_df[plot_var], threshold=threshold, ret_idx = True)\n",
    "            first = False\n",
    "        else:\n",
    "            series = rebase_series(country_df[plot_var], trim_idx=trim_idx)\n",
    "        \n",
    "        series = pd.Series(series).rolling(window=mean_window).mean()\n",
    "        axs[row_idx, col_idx].plot(series, label=plot_vars[plot_var])\n",
    "    if log_scale:\n",
    "        axs[row_idx, col_idx].set_yscale(\"log\", basey=2)                                 \n",
    "    axs[row_idx, col_idx].set_title(title)\n",
    "    if row_idx == 1:\n",
    "        axs[row_idx, col_idx].set_xlabel(f\"Days since {threshold}th case\")\n",
    "    axs[row_idx, col_idx].legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_country(full_df, country, threshold, mean_window=3):\n",
    "    fig, axs = plt.subplots(2, 2)\n",
    "    plt.rcParams.update({'font.size': 12})\n",
    "    #plt.subplots_adjust(wspace=0.4,hspace=1.3)\n",
    "    fig.set_size_inches(16, 10)\n",
    "    fig.suptitle(f'{country} :: Comparison over time')\n",
    "    country_df = full_df.loc[full_df[\"Country/Region\"]==country]\n",
    "    daily_vars = { 'confirmed' : \"New Cases\",\n",
    "                 'deaths' : \"New Deaths\",\n",
    "                 'recovered' : \"New Recovered\",\n",
    "                 'net_cases' : \"Net Cases\"    \n",
    "    }\n",
    "    plot_panel(axs, 0, 0, country_df, daily_vars, threshold, \n",
    "               \"Daily\", mean_window=mean_window)\n",
    "    plot_panel(axs, 1, 0, country_df, daily_vars, threshold, \n",
    "               \"Daily (Log)\", mean_window=mean_window, log_scale=True)\n",
    "    cum_vars = { 'confirmed_total' : \"Total Confirmed Cases\",\n",
    "                 'deaths_total' : \"Total Deaths\",\n",
    "                 'recovered_total' : \"Recovered\",\n",
    "                 'active_cases' : \"Active Cases\"    \n",
    "    }\n",
    "    plot_panel(axs, 0, 1, country_df, cum_vars, threshold,\n",
    "               \"Cumulative\")\n",
    "    plot_panel(axs, 1, 1, country_df, cum_vars, threshold,\n",
    "               \"Cumulative (Log)\", log_scale=True)\n",
    "    plt.savefig(f'figures/{country}_timeComp_{threshold}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_country_list(full_df, countries, threshold=25):\n",
    "    for country in countries:\n",
    "        plot_country(full_df, country, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_log_growth(full_df, countries, mean_window=3, days=45):\n",
    "    #plot_var = 'deaths_log_growth'\n",
    "    #threshold= 0.5\n",
    "    # mean_window = 3\n",
    "    # days = 45\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    plt.rcParams.update({'font.size': 12})\n",
    "    #plt.subplots_adjust(wspace=0.4,hspace=1.3)\n",
    "    fig.set_size_inches(16, 6)\n",
    "\n",
    "    labels = labels = [i * 15 for i in range(0, days // 15 + 1)]\n",
    "    for country in countries:\n",
    "        country_df = full_df.loc[full_df['Country/Region'] == country]\n",
    "        death_series = country_df['deaths_log_growth'].rolling(window=mean_window).mean()\n",
    "        confirmed_series = country_df['confirmed_log_growth'].rolling(window=mean_window).mean()\n",
    "        #series = rebase_series(country_df[plot_var], threshold=threshold)\n",
    "        axs[0].plot(death_series[-days:], label=country)\n",
    "        axs[1].plot(confirmed_series[-days:], label=country)\n",
    "    axs[0].set_title(f'Deaths :: Log Growth (last {days} days)')\n",
    "    axs[1].set_title(f'Confirmed Cases :: Log Growth (last {days} days)')\n",
    "    for idx in [0,1]:\n",
    "        axs[idx].set_xticks(labels)\n",
    "        axs[idx].set_xticklabels(labels)\n",
    "    axs[1].legend()\n",
    "    plt.savefig(f'figures/country_logGrowth_{days}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_normalised(full_df, countries, mean_window=3, days=60):\n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    plt.rcParams.update({'font.size': 12})\n",
    "    #plt.subplots_adjust(wspace=0.4,hspace=1.3)\n",
    "    fig.set_size_inches(16, 6)\n",
    "\n",
    "    labels = [i * 15 for i in range(0, days // 15 + 1)]\n",
    "    for country in countries:\n",
    "        country_df = full_df.loc[full_df['Country/Region'] == country]\n",
    "        death_series = country_df['confirmed_total_norm']\n",
    "        confirmed_series = country_df['deaths_total_norm']\n",
    "        #series = rebase_series(country_df[plot_var], threshold=threshold)\n",
    "        axs[0].plot(death_series[-days:], label=country)\n",
    "        axs[1].plot(confirmed_series[-days:], label=country)\n",
    "    axs[0].set_title(f'Deaths, per Million population :: Log Growth (last {days} days)')\n",
    "    axs[1].set_title(f'Confirmed Cases, per Million population :: Log Growth (last {days} days)')\n",
    "    for idx in [0,1]:\n",
    "        axs[idx].set_yscale(\"log\", basey=10) \n",
    "        axs[idx].set_xticks(labels)\n",
    "        axs[idx].set_xticklabels(labels)\n",
    "    axs[1].legend()\n",
    "    plt.savefig(f'figures/country_normPop_{days}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_warnings('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refreshed at 2020-04-23 13:46:37.284225\n"
     ]
    }
   ],
   "source": [
    "reload_module(fetch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch_data.map_name_to_ISOcode('World')\n",
    "\n",
    "# continents = pd.read_csv('assets/country_continent.csv')\n",
    "\n",
    "# continents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Fetch global corona virus numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROJECT_FOLDER = '/Users/richie/Dropbox/Records/Education/2019-20_BGSE_MScDataScience/Modules/DS_Trimester02/DataVisualisation/PartB/Project/dashboard/minimal_dash_flask'\n",
    "# # APP_PATH = \"dashboard/minimal_dash_flask/\"\n",
    "# if os.getcwd() != PROJECT_FOLDER:\n",
    "#     #os.chdir(APP_PATH)\n",
    "#     os.chdir(PROJECT_FOLDER)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/richie/Dropbox/Records/Education/2019-20_BGSE_MScDataScience/Modules/DS_Trimester03/DS_MastersProject/dashboard/cv_dashboard'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cc  = coco.CountryConverter()\n",
    "\n",
    "# cc.valid_class\n",
    "\n",
    "# oecd = set(cc.data.loc[~cc.data['OECD'].isna(),'name_short'])\n",
    "\n",
    "# other_high_income = set(cc.data.loc[cc.data['Cecilia2050'] == 'HI', 'name_short'])\n",
    "\n",
    "# eu = cc.data.loc[cc.data['Cecilia2050'] == 'EU', 'name_short']\n",
    "\n",
    "# other_high_income - oecd\n",
    "\n",
    "# oecd\n",
    "\n",
    "# oecd - other_high_income.union(eu)\n",
    "\n",
    "# cc.data['Cecilia2050'].unique()\n",
    "\n",
    "\n",
    "# cc.data.columns\n",
    "\n",
    "# # cc.data.loc[cc.data['Cecilia2050'] == 'EU', 'name_short'] # European Union\n",
    "# # cc.data.loc[cc.data['Cecilia2050'] == 'HI', 'name_short'] # Other High Income\n",
    "# # cc.data.loc[cc.data['Cecilia2050'] == 'BX', 'name_short'] # Emerging markets, BRICS+\n",
    "# # cc.data.loc[cc.data['Cecilia2050'] == 'RoW', 'name_short'] # Rest of World\n",
    "\n",
    "\n",
    "# # EU : European Union\n",
    "# # HI : Other High Income\n",
    "# # BX : Emerging Markets\n",
    "# # RoW : Rest of World\n",
    "\n",
    "# cc.OECDas('ISO3')\n",
    "\n",
    "# cc.EU28as('ISO3')\n",
    "\n",
    "# # country = 'Afghanistan'\n",
    "# # m_df = cv_merged_df.copy()\n",
    "\n",
    "# # first_date = m_df.columns.get_loc(\"1/22/20\")\n",
    "# # sf = m_df.loc[(m_df['Country/Region'] == country) &\n",
    "# #                     (m_df['Province/State'].isna())]\n",
    "# # sf = sf.iloc[:,first_date:].T\n",
    "\n",
    "# # sf['Country/Region'] = country\n",
    "# # codes = map_name_to_ISOcode(country)\n",
    "# # sf['ISO3166_alpha2'] = codes[0]\n",
    "# # sf['ISO3166_alpha3'] = codes[1]\n",
    "# # sf['ISO3166_numeric'] = codes[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Purging cached files...\n",
      "\t+ File [ assets/full_df.csv ] not found. Cannot remove...\n",
      "\t+ File [ assets/merged_df_global.csv ] not found. Cannot remove...\n",
      "\t+ Removing file [ assets/coronaVirus_global.csv ]...\n",
      "\t+ File [ assets/coronaVirus_US.csv ] not found. Cannot remove...\n",
      "\t+ Removing file [ assets/ISO_codes.csv ]...\n",
      "\t+ File [ assets/wb_indicators.csv ] not found. Cannot remove...\n",
      ">> File [ merged_df_global.csv ] not found. Fetching...\n",
      ">> File [ coronaVirus_global.csv ] not found. Fetching...\n",
      ">> File [ ISO_codes.csv ] not found. Fetching...\n",
      ">> Before name fixes:\n",
      "\t+ [ Bahamas ] not found...\n",
      "\t+ [ Congo (Brazzaville) ] not found...\n",
      "\t+ [ Congo (Kinshasa) ] not found...\n",
      "\t+ [ Diamond Princess ] not found...\n",
      "\t+ [ Gambia ] not found...\n",
      "\t+ [ Holy See ] not found...\n",
      "\t+ [ Taiwan* ] not found...\n",
      "\t+ [ US ] not found...\n",
      "\t+ [ West Bank and Gaza ] not found...\n",
      "\t+ [ MS Zaandam ] not found...\n",
      ">> After name fixes:\n",
      "\t+ [ Other ] not found...\n",
      ">> Before summarise countries:\n",
      ">> File  [ ISO_codes.csv ] found. Checking age... \n",
      "\t+ File  [ ISO_codes.csv ] not expired. Load from disk...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/r_env/lib/python3.7/site-packages/pandas/core/series.py:679: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/anaconda3/envs/r_env/lib/python3.7/site-packages/pandas/core/algorithms.py:1926: RuntimeWarning: invalid value encountered in subtract\n",
      "  out_arr[res_indexer] = arr[res_indexer] - arr[lag_indexer]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t+ [Australia] not found...\n",
      "\t+ [Canada] not found...\n",
      "\t+ [Other] not found...\n",
      "\t+ [China] not found...\n",
      ">> After summarise countries:\n",
      "\t+ No failures found.\n",
      ">> Fetching World Bank Indicators...\n",
      ">> File [ wb_indicators.csv ] not found. Fetching...\n",
      "Request URL [ https://api.worldbank.org/v2/country/all/indicator/SP.POP.TOTL?format=json&mrnev=1 ]\n",
      "Request URL [ https://api.worldbank.org/v2/country/all/indicator/NY.GDP.MKTP.CD?format=json&mrnev=1 ]\n",
      "Request URL [ https://api.worldbank.org/v2/country/all/indicator/SP.DYN.LE00.MA.IN?format=json&mrnev=1 ]\n",
      "Request URL [ https://api.worldbank.org/v2/country/all/indicator/SP.DYN.LE00.FE.IN?format=json&mrnev=1 ]\n",
      ">> Merging data...\n",
      "\t+ Saving to [ assets/merged_df_global.csv ]\n",
      ">> File [ full_df.csv ] not found. Fetching...\n",
      ">> Building full df...\n",
      "\t+ Complete.\n"
     ]
    }
   ],
   "source": [
    "full_df, cv_merged_df, iso_codes_df, indicator_df = fetch_data.fetch_all(purge=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Groups\n",
    "+ Date\n",
    "+ Country information\n",
    "    + Country Name\n",
    "    + Province / State\n",
    "    + Continent\n",
    "    + International Organisation\n",
    "    + OECD\n",
    "    + G8\n",
    "+ Confirmed / Deaths / Recovered / Active\n",
    "    + Cumulative\n",
    "    + Delta\n",
    "    + Cumulative norm\n",
    "    + Log cumulative\n",
    "    + Log delta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_df_bak = full_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = full_df_bak.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['Date'] = pd.to_datetime(full_df.index)\n",
    "full_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.loc[(full_df['Country/Region']=='United States') &\n",
    "            (full_df['Date']=='2020-04-19')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_columns = [ 'ISO3166_alpha3', 'population', 'gdp_total',\n",
    "                  'lifeExp_male', 'lifeExp_female', 'DisplayName']\n",
    "cv_df = cv_df[merge_columns]\n",
    "full_df = pd.merge(full_df, cv_df, how='left', on='ISO3166_alpha3')\n",
    "# Fix the world name\n",
    "#full_df.loc[full_df[\"ISO3166_alpha3\"] == 'WLD', \"Name\"] = 'World'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df3 = full_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df3.loc[tmp_df3['ISO3166_alpha3']=='USA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cv_merged_df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = ['Spain', 'Italy', 'China', 'Korea, South', 'United States', 'Singapore']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Richard Keely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sources\n",
    "For this project, the principal source used was the John Hopkins University's dataset on corona virus cases. This dataset require a surprising amount of cleaning and heavy reshaping to be usable in the form used for this project. In addition, a number of derived statistics were created to allow things like the growth rate and the active statistics to be examined. In addition, to allow for more useful comparisons, I merged it with two additional datasets, the ISO3166 codes available (via some web-scraping) from the CIA World Factbook and then a number of indicators fetched from the World Bank using an API access.\n",
    "\n",
    "The idea was to make this into an interactive dashboard, but a rather pernicious bug in my caching functions lead to a quite literal 11th hour switch back to static graphics, which are presented below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisations and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_plot(full_df, countries, y_lim=2**15, x_lim=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot is a reimplementation of one from the [New York Times' Upshot blog](https://www.nytimes.com/interactive/2020/03/21/upshot/coronavirus-deaths-by-country.html). It allows for a clear view of the growth of the cumulative statistics over time. Here you can see two plots for the countries that I thought would be most interesting to look at, Spain, Italy, China, South Korea, the United States and Singapore (used in all of the plots). Here, it can be seen that the growth rates for most of the countries is now saturating, though the US has not yet reached that point and while Singapore had initially been doing quite well, it appears to now be experiencing a surge in cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code for this plots everything together, so I've inserted the images instead. For all of the plots we can see the daily and cumulative view of our four main variables over time. For the daily variables, a three period rolling average was used to smooth out some of the turbulence caused by the coarseness of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plot_country_list(full_df, countries, threshold=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![China](figures/China_timeComp_25.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot for China is the most promising and most similar to the expected theory; after an initial surge, the cases are brought under control and the number of active cases decays towards zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SouthKorea](figures/SouthKorea_timeComp_25.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "South Korea is also quite promising, showing a similar trend to China, but at an earlier point in the cycle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Spain](figures/Spain_timeComp_25.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Italy](figures/Italy_timeComp_25.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spain and Italy appear, unfortunately to be still in the midst of the worst part of the curve. While the net increase in the number of active cases is decreasing, the cumulative case load still hasn't peaked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![United States](figures/UnitedStates_timeComp_25.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The United States is even earlier in the cycle and, indeed merits analysis at a more granular level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Singapore](figures/Singapore_timeComp_25.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally Singapore which had appeared to have missed the worst of the epidemic is now experiencing a surge in cases, though whether this will be as bad as that experienced in Europe and the US remains to be seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_log_growth(full_df, countries, mean_window=3, days=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I looked at the log growth of deaths and confirmed cases over time, again using a rolling average to smooth the noise. Here it can be seen that for most countries the last two weeks have been largely in the right direction after much more volatility before that as reporting and testing likely revealed more of the underlying cases. Interestingly again, Singapore appears to be in a much earlier stage of the cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_normalised(full_df, countries, mean_window=3, days=75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, here I look at deaths and cases normalised by population, to see get some understanding of the the true toll of the crisis in different countries. One interesting thing from this plot is that while it took time to do so, Spain appears to be doing worse across both the deaths and confirmed cases than Italy. This suggests that Spain may not have been able to capitalise on the time and learning from Italy. In addition, it appears that the US may surpass both Spain and Italy. Here again, Singapore's later entry into the crisis is visible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "211px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
